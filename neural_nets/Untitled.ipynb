{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesma separacao do exercicio anterior (SVM) salvas em csv\n",
    "X_train = pd.read_csv('../data/X_train.csv')\n",
    "X_test = pd.read_csv('../data/X_test.csv')\n",
    "y_train = pd.read_csv('../data/y_train.csv')\n",
    "y_test = pd.read_csv('../data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizando os dados\n",
    "\n",
    "# Flagando paraa separar depois\n",
    "X_train['tipo'] = 'train'\n",
    "X_test['tipo'] = 'test'\n",
    "\n",
    "#juntando datasets para normalizar em conjunto\n",
    "X = pd.concat([X_train,X_test])\n",
    "\n",
    "# Normalizando 0 e 1\n",
    "types = X['tipo']\n",
    "X = X.drop(['tipo'],axis=1)\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "# voltando a coluna de tipo para separa-los novamente\n",
    "X['tipo'] = types\n",
    "# voltando para o dado original\n",
    "X_train = X.loc[X['tipo'] == 'train'].drop(['tipo'],axis=1)\n",
    "X_test =  X.loc[X['tipo'] == 'test'].drop(['tipo'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pred_classifier(X_train, X_test, y_train, y_test,\n",
    "                          hl_size, activation, alpha,epocas):\n",
    "    \n",
    "    print(alpha)\n",
    "    print(hl_size)\n",
    "    # prepara classificador\n",
    "    clf = MLPClassifier(solver='lbfgs', # resolve com hasseane, mais rapido\n",
    "                        alpha=alpha,\n",
    "                        hidden_layer_sizes=hl_size,\n",
    "                        activation = activation,\n",
    "                        max_iter = epocas,\n",
    "                        random_state=1)\n",
    "    # treina\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # calcula erros\n",
    "    p = precision_score(y_test, y_pred, average='micro')\n",
    "    r = recall_score(y_test, y_pred, average='micro')\n",
    "    auc = roc_auc_score(y_test, y_pred, average='micro')\n",
    "    return p,r,auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = 'Todas as Caracteristicas'\n",
    "camadas_ocultas = [\n",
    "  (10,1), #  uma camada oculta com 1000 neuronios\n",
    "  (10, 15), # duas camadas ocultas com 1000 neuronios e 200\n",
    "  (20, 15), # tres camadas ocultas\n",
    "  (10, 30, 10) # tres camadas ocultas\n",
    "]\n",
    "funcao_ativacao = ['logistic', 'relu']\n",
    "alpha = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "epocas = [500, 1000, 2000, 5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "(10, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/favoretti/.local/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "(10, 1)\n",
      "0.1\n",
      "(10, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d9a2702039f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     p,r,auc = train_pred_classifier(X_train.head(10), X_test.head(10),\n\u001b[1;32m      8\u001b[0m                                           \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                           layer_conf, f, a,epoch)\n\u001b[0m\u001b[1;32m     10\u001b[0m                     one_line_response = {\n\u001b[1;32m     11\u001b[0m                         \u001b[0;34m'tipo'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtipo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-617800d8399b>\u001b[0m in \u001b[0;36mtrain_pred_classifier\u001b[0;34m(X_train, X_test, y_train, y_test, hl_size, activation, alpha, epocas)\u001b[0m\n\u001b[1;32m     12\u001b[0m                         random_state=1)\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# treina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \"\"\"\n\u001b[1;32m    972\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 973\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0;32m--> 383\u001b[0;31m                             intercept_grads, layer_units)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0miprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mpgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    326\u001b[0m         _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001b[1;32m    327\u001b[0m                        \u001b[0mpgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                        isave, dsave, maxls)\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mtask_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'FG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_dicts = []\n",
    "for t in tipo:\n",
    "    for layer_conf in camadas_ocultas:\n",
    "        for f in funcao_ativacao:\n",
    "            for a in alpha:\n",
    "                for epoch in epocas:\n",
    "                    p,r,auc = train_pred_classifier(X_train.head(10), X_test.head(10),\n",
    "                                          y_train.head(10), y_test.head(10),\n",
    "                                          layer_conf, f, a,epoch)\n",
    "                    one_line_response = {\n",
    "                        'tipo' : tipo,\n",
    "                        'camadas_ocultas' : layer_conf,\n",
    "                        'funcao_ativacao' : f,\n",
    "                        'num_epocas' : epoch,\n",
    "                        'alpha': a,\n",
    "                        'precision': p,\n",
    "                        'recall': r,\n",
    "                        'auc': auc\n",
    "                    }\n",
    "                    all_dicts.append(one_line_response)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0.001,\n",
       "  'auc': 0.20000000000000001,\n",
       "  'camadas_ocultas': (10, 1),\n",
       "  'funcao_ativacao': 'logistic',\n",
       "  'num_epocas': 500,\n",
       "  'precision': 0.20000000000000001,\n",
       "  'recall': 0.20000000000000001,\n",
       "  'tipo': 'Todas as Caracteristicas'},\n",
       " {'alpha': 0.01,\n",
       "  'auc': 0.29999999999999999,\n",
       "  'camadas_ocultas': (10, 1),\n",
       "  'funcao_ativacao': 'logistic',\n",
       "  'num_epocas': 500,\n",
       "  'precision': 0.29999999999999999,\n",
       "  'recall': 0.29999999999999999,\n",
       "  'tipo': 'Todas as Caracteristicas'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>auc</th>\n",
       "      <th>camadas_ocultas</th>\n",
       "      <th>funcao_ativacao</th>\n",
       "      <th>num_epocas</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>logistic</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Todas as Caracteristicas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.3</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>logistic</td>\n",
       "      <td>500</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Todas as Caracteristicas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  auc camadas_ocultas funcao_ativacao  num_epocas  precision  recall  \\\n",
       "0  0.001  0.2         (10, 1)        logistic         500        0.2     0.2   \n",
       "1  0.010  0.3         (10, 1)        logistic         500        0.3     0.3   \n",
       "\n",
       "                       tipo  \n",
       "0  Todas as Caracteristicas  \n",
       "1  Todas as Caracteristicas  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
